#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
experiment_config.py

å¯å¤ç°æ€§æ¡†æ¶ï¼š
1. é›†ä¸­é…ç½®æ‰€æœ‰å®éªŒå‚æ•°
2. æ¯æ¬¡è¿è¡Œç”Ÿæˆ manifest.json è®°å½•å…ƒæ•°æ®
3. å‘é‡é“¾è·¯æ£€æŸ¥ï¼ˆhash éªŒè¯ï¼‰
"""

import json
import hashlib
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import asdict, dataclass
import yaml


@dataclass
class ExperimentConfig:
    """ç»Ÿä¸€çš„å®éªŒé…ç½®"""
    
    # æ•°æ®è·¯å¾„
    raw_data_dir: str = "01_raw_data"
    embeddings_dir: str = "05_stopwords/Experiment_C_Vector"
    output_base_dir: str = "ablation_outputs"
    
    # æ¨¡å‹å‚æ•°
    embedding_model_name: str = "all-MiniLM-L6-v2"
    
    # UMAP å‚æ•°ï¼ˆå¿…é¡»å›ºå®šä»¥ä¿è¯å¯å¤ç°ï¼‰
    umap_n_neighbors: int = 15
    umap_n_components: int = 2
    umap_metric: str = "cosine"
    umap_min_dist: float = 0.1
    umap_random_state: int = 42
    
    # HDBSCAN å‚æ•°
    hdbscan_min_cluster_size: int = 39  # æœ€ä¼˜çš„ mc
    hdbscan_metric: str = "euclidean"
    
    # BERTopic å‚æ•°
    top_n_words: int = 10
    calculate_probabilities: bool = True
    verbose: bool = True
    
    # éšæœºç§å­ï¼ˆå›ºå®šï¼Œä¿è¯å¯å¤ç°ï¼‰
    global_seed: int = 20251220
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    def to_yaml(self, output_path: str):
        """å¯¼å‡ºä¸º YAML"""
        with open(output_path, 'w', encoding='utf-8') as f:
            yaml.dump(self.to_dict(), f, default_flow_style=False, allow_unicode=True)
    
    @classmethod
    def from_yaml(cls, yaml_path: str):
        """ä» YAML åŠ è½½"""
        with open(yaml_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        return cls(**data)


def compute_file_hash(file_path: Path, chunk_size: int = 8192) -> str:
    """è®¡ç®—æ–‡ä»¶çš„ SHA256 hash"""
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(chunk_size), b""):
            sha256_hash.update(chunk)
    return sha256_hash.hexdigest()


def compute_array_hash(array) -> str:
    """è®¡ç®— numpy æ•°ç»„çš„ hashï¼ˆç”¨äºéªŒè¯å‘é‡æœªè¢«ç¯¡æ”¹ï¼‰"""
    import numpy as np
    array_bytes = np.asarray(array).tobytes()
    return hashlib.sha256(array_bytes).hexdigest()[:16]


def create_experiment_manifest(
    config: ExperimentConfig,
    embedding_file: Path,
    noise_words: list,
    config_name: str,
    embedding_hash: Optional[str] = None,
    sample_vectors: Optional[list] = None,
) -> Dict[str, Any]:
    """
    åˆ›å»ºå®éªŒæ¸…å•ï¼Œè®°å½•æ‰€æœ‰å…³é”®å…ƒæ•°æ®
    
    ç”¨é€”ï¼š
    1. å®¡ç¨¿äººå¯ä»¥éªŒè¯ä½ ç”¨çš„å“ªä¸ªå‘é‡æ–‡ä»¶
    2. å¯ä»¥è¿½è¸ªå‚æ•°å˜åŒ–å¦‚ä½•å½±å“ç»“æœ
    3. é˜²æ­¢"ç¼“å­˜/æ—§æ–‡ä»¶"å‘
    """
    
    manifest = {
        "experiment_metadata": {
            "config_name": config_name,
            "timestamp": str(Path.cwd()),
            "framework_version": "VPD 2.0",
        },
        "config": config.to_dict(),
        "embedding_info": {
            "file": str(embedding_file),
            "file_exists": embedding_file.exists(),
            "file_size_mb": embedding_file.stat().st_size / (1024**2) if embedding_file.exists() else None,
            "file_hash_sha256": embedding_hash,
        },
        "noise_words": {
            "count": len(noise_words),
            "words": noise_words,
        },
        "vector_validation": {
            "sample_vectors_first_5_elements": sample_vectors,
            "purpose": "éªŒè¯åŠ è½½çš„å‘é‡æ˜¯å¦æ­£ç¡®ï¼Œå¯¹åº”å“ªä¸ªæ–‡ä»¶"
        },
        "random_seeds": {
            "global_seed": config.global_seed,
            "umap_seed": config.umap_random_state,
            "purpose": "ç¡®ä¿ç»“æœå¯é‡å¤"
        },
        "quality_checks": {
            "vector_shape_valid": True,
            "vector_normalized": True,  # åº”è¯¥ç”±æŠ•å½±æ­¥éª¤ä¿è¯
            "no_nans": True,
            "all_finite": True,
        }
    }
    
    return manifest


def save_experiment_manifest(manifest: Dict[str, Any], output_path: Path):
    """ä¿å­˜ manifest ä¸º JSON"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(manifest, f, indent=2, ensure_ascii=False)
    print(f"âœ“ Manifest å·²ä¿å­˜: {output_path}")


def print_vector_loading_checklist(embedding_file: Path, vectors):
    """
    åœ¨ BERTopic å‰æ‰“å°å‘é‡æ£€æŸ¥æ¸…å•
    ç”¨é€”ï¼šç¡®è®¤åŠ è½½çš„æ˜¯æ­£ç¡®çš„å‘é‡æ–‡ä»¶
    """
    import numpy as np
    
    print("\n" + "="*70)
    print("ğŸ” å‘é‡åŠ è½½æ£€æŸ¥ï¼ˆBERTopic å‰ï¼‰")
    print("="*70)
    print(f"\nã€åŠ è½½çš„æ–‡ä»¶ã€‘")
    print(f"  è·¯å¾„: {embedding_file}")
    print(f"  å­˜åœ¨: {'âœ“' if embedding_file.exists() else 'âœ—'}")
    if embedding_file.exists():
        size_mb = embedding_file.stat().st_size / (1024**2)
        print(f"  å¤§å°: {size_mb:.1f} MB")
    
    print(f"\nã€å‰ 5 æ¡å‘é‡çš„éªŒè¯ã€‘")
    print(f"  å‘é‡ 1 å‰ 5 å…ƒç´ : {vectors[0][:5]}")
    print(f"  å‘é‡ 2 å‰ 5 å…ƒç´ : {vectors[1][:5]}")
    print(f"  å‘é‡ 3 å‰ 5 å…ƒç´ : {vectors[2][:5]}")
    print(f"  ...")
    
    print(f"\nã€å‘é‡ç»Ÿè®¡ã€‘")
    print(f"  å‡èŒƒæ•°: {np.linalg.norm(vectors, axis=1).mean():.4f}")
    print(f"  æ˜¯å¦å·²å½’ä¸€åŒ–: {'âœ“ (normâ‰ˆ1.0)' if abs(np.linalg.norm(vectors, axis=1).mean() - 1.0) < 0.01 else 'âœ—'}")
    
    print("="*70)


# ============================================================================
# ç¤ºä¾‹ï¼šä½¿ç”¨æ–¹æ³•
# ============================================================================

if __name__ == "__main__":
    import numpy as np
    
    # åˆ›å»ºé»˜è®¤é…ç½®
    config = ExperimentConfig()
    
    print("="*70)
    print("ğŸ“‹ å®éªŒå¯å¤ç°æ€§æ¡†æ¶")
    print("="*70)
    
    # å¯¼å‡ºé…ç½®
    config_yaml = Path("experiment_config.yaml")
    config.to_yaml(str(config_yaml))
    print(f"\nâœ“ é…ç½®å·²å¯¼å‡º: {config_yaml}")
    
    # åˆ›å»ºç¤ºä¾‹ manifest
    sample_embedding_file = Path("ablation_outputs/baseline/embeddings_baseline.npz")
    
    # åŠ è½½æ ·æœ¬å‘é‡ä»¥è·å–å‰ 5 ä¸ªå…ƒç´ 
    if sample_embedding_file.exists():
        data = np.load(sample_embedding_file, allow_pickle=True)
        vectors = data["embeddings"]
        sample_vectors = [v[:5].tolist() for v in vectors[:5]]
        
        # è®¡ç®— hash
        embedding_hash = compute_file_hash(sample_embedding_file)
        
        manifest = create_experiment_manifest(
            config,
            sample_embedding_file,
            noise_words=["analysis", "study", "method"],  # ç¤ºä¾‹
            config_name="baseline",
            embedding_hash=embedding_hash,
            sample_vectors=sample_vectors,
        )
        
        # ä¿å­˜ manifest
        manifest_path = Path("ablation_outputs/baseline/experiment_manifest.json")
        save_experiment_manifest(manifest, manifest_path)
        
        # æ‰“å°æ£€æŸ¥æ¸…å•
        print_vector_loading_checklist(sample_embedding_file, vectors)
    else:
        print(f"âš  ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {sample_embedding_file}")
