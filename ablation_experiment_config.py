#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VPD æ¶ˆèå®éªŒé…ç½®ä¸æ‰§è¡Œ
æ‹†åˆ†å™ªå£°æ–¹å‘ï¼Œé€æ­¥æŠ•å½±ï¼Œçœ‹å“ªä¸ªåˆ†é‡çœŸçš„é©±åŠ¨äº†æ€§èƒ½æ”¹è¿›
"""

from dataclasses import dataclass
from typing import List, Dict

# ============================================================================
# å™ªå£°è¯åˆ†ç»„ï¼šM/S/B/Anatomy
# ============================================================================

@dataclass
class NoiseWordGroups:
    """å™ªå£°è¯åˆ†ç»„å®šä¹‰"""
    
    # Group M: Methodologyï¼ˆæ–¹æ³•è®ºå™ªéŸ³ï¼‰
    M = [
        "analysis", "study", "results", "method", "conclusion", "data",
        "using", "performed", "evaluated", "aim", "background", "investigated",
    ]
    
    # Group S: Statisticsï¼ˆç»Ÿè®¡æè¿°å™ªéŸ³ï¼‰
    S = [
        "significant", "significantly", "increased", "decreased", "higher",
        "lower", "compared", "group", "rate", "ratio", "value", "associated",
        "difference", "respectively",
    ]
    
    # Group B: Broad backgroundï¼ˆå®½æ³›èƒŒæ™¯å™ªéŸ³ï¼‰
    B = [
        "clinical", "patient", "patients", "treatment", "disease", "infection",
        "cases", "years", "time", "effect", "various", "regarding", "reported",
        "recent",
    ]
    
    # Group Anatomy: è§£å‰–/å¯¹è±¡è¯ï¼ˆå¯¹ç…§ç»„ï¼Œç†è®ºä¸Šä¸åº”è¯¥åˆ ï¼‰
    Anatomy = [
        "gastric", "stomach", "mucosa", "biopsy", "human", "tissue",
        "samples", "specimens"
    ]
    
    @classmethod
    def get_groups(cls) -> Dict[str, List[str]]:
        """è¿”å›æ‰€æœ‰åˆ†ç»„"""
        return {
            "M": cls.M,
            "S": cls.S,
            "B": cls.B,
            "Anatomy": cls.Anatomy,
        }
    
    @classmethod
    def get_combined(cls, groups: List[str]) -> List[str]:
        """ç»„åˆå¤šä¸ªåˆ†ç»„"""
        all_groups = cls.get_groups()
        result = []
        for g in groups:
            if g in all_groups:
                result.extend(all_groups[g])
        return result


# æ¶ˆèå®éªŒé…ç½®
ABLATION_CONFIGS = {
    "baseline": {
        "name": "Baselineï¼ˆæ— æŠ•å½±ï¼‰",
        "noise_words": [],
        "description": "Control: åŸå§‹èåˆå‘é‡ï¼Œæ— å»å™ª"
    },
    "M_S": {
        "name": "æŠ•å½± M+Sï¼ˆæ ¸å¿ƒèƒŒæ™¯å™ªå£°ï¼‰",
        "noise_words": NoiseWordGroups.get_combined(["M", "S"]),
        "description": "ä»…ç§»é™¤æ–¹æ³•è®º+ç»Ÿè®¡å™ªéŸ³ï¼Œä¿ç•™èƒŒæ™¯å’Œå¯¹è±¡è¯"
    },
    "M_S_B": {
        "name": "æŠ•å½± M+S+Bï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰",
        "noise_words": NoiseWordGroups.get_combined(["M", "S", "B"]),
        "description": "ç§»é™¤æ–¹æ³•è®ºã€ç»Ÿè®¡ã€èƒŒæ™¯å™ªéŸ³ï¼Œä¿ç•™è§£å‰–è¯"
    },
    "M_S_B_Anatomy": {
        "name": "æŠ•å½± M+S+B+Anatomyï¼ˆå…¨éƒ¨å™ªå£°ï¼‰",
        "noise_words": NoiseWordGroups.get_combined(["M", "S", "B", "Anatomy"]),
        "description": "ä½ ç°åœ¨è¿™ç‰ˆï¼šå®Œæ•´å»å™ªï¼ˆåŒ…æ‹¬è§£å‰–/å¯¹è±¡è¯ï¼‰"
    },
}


def print_ablation_summary():
    """æ‰“å°æ¶ˆèå®éªŒé…ç½®æ€»ç»“"""
    print("=" * 80)
    print("ğŸ§ª VPD æ¶ˆèå®éªŒé…ç½®")
    print("=" * 80)
    
    for key, config in ABLATION_CONFIGS.items():
        print(f"\n{key.upper()}: {config['name']}")
        print(f"  å™ªå£°è¯æ•°: {len(config['noise_words'])}")
        print(f"  è¯´æ˜: {config['description']}")
        if config['noise_words']:
            print(f"  è¯æ±‡æ ·ä¾‹: {', '.join(config['noise_words'][:5])}...")
    
    print("\n" + "=" * 80)
    print("ã€å…³é”®é—®é¢˜ã€‘")
    print("  Q1: M+S (26è¯) èƒ½åšåˆ°å¤šå°‘æ•ˆæœï¼Ÿ")
    print("  Q2: åŠ B (13è¯) åæ€§èƒ½å¦‚ä½•å˜ï¼Ÿ")
    print("  Q3: Anatomy (8è¯) æ˜¯å¦åº”è¯¥æŠ•å½±ï¼ˆè¿˜æ˜¯æœ‰ç›Šä¿¡æ¯ï¼‰ï¼Ÿ")
    print("  Q4: å“ªä¸ªåˆ†ç»„è´¡çŒ®æœ€å¤§çš„ C_v æå‡ï¼Ÿ")
    print("=" * 80)


if __name__ == "__main__":
    print_ablation_summary()
    
    # è¾“å‡ºåˆ†ç»„ç»Ÿè®¡
    groups = NoiseWordGroups.get_groups()
    print("\nã€åˆ†ç»„ç»Ÿè®¡ã€‘")
    for name, words in groups.items():
        print(f"{name}: {len(words)} ä¸ªè¯")
    
    # æ€»è¯æ•°
    all_words = set()
    for words in groups.values():
        all_words.update(words)
    print(f"æ€»è®¡ï¼ˆå»é‡ï¼‰: {len(all_words)} ä¸ªè¯")
